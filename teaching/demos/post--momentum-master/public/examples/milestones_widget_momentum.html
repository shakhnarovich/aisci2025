<!doctype html>
<meta charset="utf-8">
<html>
<head>
<script src="../assets/lib/template.v1.js"></script>
<script src="../assets/lib/lib.js"></script>
<script src="../assets/utils.js"></script>
<script src="../assets/stochastic_milestones.js"></script>
<link rel="stylesheet" href="../assets/lib/katex.min.css">
<link rel="stylesheet" type="text/css" href="../assets/widgets.css">
<script src="../assets/lib/auto-render.min.js"></script>
<script src="../assets/lib/katex.min.js"></script>

</head> 
<body>
<script type="text/javascript">
function renderMath(elem) {
  renderMathInElement(
      elem,
      {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
          ]
      }
  );
  }

</script>
<dt-article class="centered">
<p>
  Instead of taking taking a step in the gradient, we move in a geometrically decaying superposition all the previous gradients. When $ \beta = 0 $ , we recover gradient descent. But for $ \beta = 0.99 $ (sometimes $ 0.999$, if things are really bad), the situation improves quite dramatically.

</p>
  <figure id="milestonesMomentumFig" style="position:relative; width:920px; height:380px">
  <figcaption style="position:absolute; text-align:left; top:30px; left:135px; width:280px; height:120px">We decompose the expected value of the objective value $\mathbf{E} f(w) - f(w^*)$ into a deterministic part <svg style="position:relative; top:2px; width:3px; height:14px; background:#e0ecf4"></svg> and a stochastic part <svg style="position:relative; top:2px; width:3px; height:14px; background:#9ebcda"></svg>. The line depicts the point where the expected errors match.</figcaption>
  <figcaption style="position:absolute; text-align:left; top:210px; left:12px; width:280px; height:120px; font-size:15px"> $\mathbf{E} f(w) - f(w^\star) $</figcaption>
  <div class="figtext" style="position:absolute; left:705px; top:11px">Step-size α = </div>
  <div class="figtext" style="position:absolute; left:464px; top:30px">Momentum β = </div>

  <div id = "sliderStep2D" style="position:absolute; left:550px; width:250px; height:100px; top:10px"></div>
  <div id = "milestonesMomentum" style="position:relative; left:15px"></div>
  </figure>
  <script>
  renderQueue = []
  renderQueue.push(function(callback) {
      var graphDiv = d3.select("#milestonesMomentum")
                   .style("width",  980 + "px")
                   .style("height", 300 + "px")
                   .style("top", "170px")
                   .style("position", "relative")
                   .style("margin-left", "auto")
                   .style("margin-right", "auto")
                   .attr("width", 920)
                   .attr("height", 500)

    var svg = graphDiv.append("svg").attr("width", 980).attr("height", 500)

    var update = renderStochasticMilestones(svg, function() {})
    var slidera = slider2D(d3.select("#sliderStep2D"), function(x,y) { update(x,y) }, 1, 100)

    // Swoopy Annotator sliderStep2D
    var annotations = [ 
      {
        "x": 0,
        "y": 0,
        "path": "M 250,96 A 32.227 32.227 0 0 0 206,62",
        "text": "Optimal parameters",
        "textOffset": [
          188,
          109
        ]
      }
    ]

  });
  renderQueue[0]()

  </script>
<p>
  Instead of taking taking a step in the gradient, we move in a geometrically decaying superposition all the previous gradients. When $ \beta = 0 $ , we recover gradient descent. But for $ \beta = 0.99 $ (sometimes $ 0.999$, if things are really bad), the situation improves quite dramatically.

</p>  
<script>renderMath(document.body)</script>
</dt-article>
</body>
